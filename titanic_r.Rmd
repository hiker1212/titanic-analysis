---
title: 'Práctica 2: Limpieza y análisis de datos '
author: "Autores: Xián Pérez Pérez y Daniel Santos Rivilla"
date: "Junio 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: tipo-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

<style>
   tbody tr:nth-child(odd){
    background-color: #f9f9f9;
  }
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,  message=FALSE, warning=FALSE)
```


******
# Introducción
******
## Presentación
En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

## Competencias
En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis. 

## Objetivos
Los objetivos concretos de esta práctica son:

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
* Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

## Descripción de la Práctica a realizar
El objetivo de esta actividad será el tratamiento de un dataset, que puede ser el creado en la práctica 1 o bien cualquier dataset libre disponible en Kaggle (https://www.kaggle.com).
Algunos ejemplos de dataset con los que podéis trabajar son:
* Red Wine Quality (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)
* Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic)

Siguiendo las principales etapas de un proyecto analítico, las diferentes tareas a realizar (y justificar) son las siguientes:

1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?
2. Integración y selección de los datos de interés a analizar.
3. Limpieza de los datos.
    1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?
    2. Identificación y tratamiento de valores extremos.
  
4. Análisis de los datos.
    1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).
    2. Comprobación de la normalidad y homogeneidad de la varianza.
    3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.
  
5. Representación de los resultados a partir de tablas y gráficas.
6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?
7. Código: Hay que adjuntar el código, preferiblemente en R, con el que se ha realizado la limpieza, análisis y representación de los datos. Si lo preferís, también podéis trabajar en Python.

## Recursos
Los siguientes recursos son de utilidad para la realización de la práctica:

* Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos. Editorial UOC.
* Megan Squire (2015). Clean Data. Packt Publishing Ltd.
* Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques. Morgan Kaufmann.
* Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369.
* Peter Dalgaard (2008). Introductory statistics with R. Springer Science & Business Media.
* Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc.
* Tutorial de Github https://guides.github.com/activities/hello-world. 

## Criterios de evaluación
Todos los apartados son obligatorios. La ponderación de los ejercicios es la siguiente:

* Los apartados 1, 2 y 6 valen 0,5 puntos.
* Los apartados 3, 5 y 7 valen 2 puntos.
* El apartado 4 vale 2,5 puntos.

Se valorará la idoneidad de las respuestas, que deberán ser claras y completas. Las diferentes etapas deberán justificarse y acompañarse del código correspondiente. También se valorará la síntesis y claridad, a través del uso de comentarios, del código resultante, así como la calidad de los datos finales analizados.

## Formato y fecha de entrega
En referente a la entrega final, hay que entregar un único fichero que contenga el enlace Github, el cual no se podrá modificar posteriormente a la fecha de entrega, donde haya:

1. Una Wiki con los nombres de los componentes del grupo y una descripción de los ficheros.
2. Un documento PDF con las respuestas a las preguntas y los nombres de los componentes del grupo. Además, al final del documento, deberá aparecer la siguiente tabla de contribuciones al trabajo, la cual debe firmar cada integrante del grupo con sus iniciales.
3. Una carpeta con el código generado para analizar los datos.
4. El fichero CSV con los datos originales.
5. El fichero CSV con los datos finales analizados.

Este documento de entrega final de la Práctica 2 se debe entregar en el espacio de Entrega y Registro de AC del aula antes de las 23:59 del día 8 de junio. No se aceptarán entregas fuera de plazo.


******
# Desarrollo de la práctica  
******

## Introducción.

Para el desarrollo de la práctica 2 de **Tipología y ciclo de vida de los datos** se ha seleccionado el dataset de Titanic expuesto en kaggle. Este dataset consta de dos ficheros .csv (test y train) en los que se encuentra recogida la información a cerca de los pasajeros del célebre crucero. Esta separación inicial está fundamentada por su objetivo de aplicar un modelo de predicción para determinar los supervivientes del accidente, de modo que uno de los conjuntos se emplee para el entrenamiento del modelo y el otro para ponerlo a prueba. Para nuestro estudio emplearemos el conjunto de entrenamiento **train** puesto que es el que cuenta con la información relativa a la supervivencia de los pasajeros.

## Carga de datos.

Se procede a llevar a cabo la carga de datos de **train.csv** y almacenarlos en forma de dataframe.

```{r Imports}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)
library(gridExtra)
library(ggcorrplot)
library(GGally)
```


```{r Carga}
# Cargamos el fichero de datos
train <- read.csv('train.csv', stringsAsFactors = FALSE)
# Verificamos la estructura del conjunto de datos
str(train)
```

## Descripción del dataset.

En este apartado se tratará de llevar a cabo una descripción detallada del conjunto de datos, con lo que se definirán los atributos del mismo, las proporciones y posibles valores de los mismos e información relevante para procesos posteriores. En primer lugar, los atributos del conjunto de datos:

* Name: un atributo de tipo texto con el nombre del pasajero.
* Sex: un atributo de tipo texto que especifica el género del pasajero. Puede tomar los valores: _male_, _female_.
* Age: atributo numérico que determina la edad del pasajero. La edad de los bebés por debajo de 12 meses se representa como una fracción del tipo 1/_meses de vida_.En caso de tratarse de una edad estimada se representa con la forma _xx.5_.
* Pclass: un atributo de tipo numérico que representa la clase a la que pertenece el pasajero. Existen las clases: _1_, _2_ y _3_ que coinciden con clase alta, clase media y clase baja respectivamente.
* Embarked: atributo de tipo texto que determina la pasarela de embarque del pasajero.Toma los valores: _S_ (Southampton), _C_ (Cherbourg) y _Q_ (Queenstown).
* Ticket: atributo de tipo texto con el código del billete del pasajero.
* Fare: atributo numérico con el precio que ha pagado el pasajero. Entendemos aquellos valores de 0, como que el pasajero en cuestión es un empleado en la nave.
* Sibsp: atributo numérico que especifica la cantidad de hermanos y/o cónyuges a bordo del barco.
* Prch:  atributo numérico que especifica la cantidad de padres y/o hijos a bordo del barco.
* Survived: atributo booleano que especifica si el pasajero ha sobrevivido al accidente o no. Se entiende _0_ como defunción y _1_ como supervivencia.
* Cabin: atributo de tipo texto que especifica el camarote en el que reside el pasajero.

Una vez definidos los atributos del conjunto, se procede a estudiar superficialmente los datos de modo que se puedan detectar ciertas tendencias o naturalezas.

```{r Únicos}
# Comprobamos los distintos valores de los atributos que parecen ser categóricos
unique(train$Survived)
unique(train$Pclass)
unique(train$Sex)
unique(train$Embarked)
```

```{r Estadísticas}
#Estadísticas básicas
summary(train)
```

Tras la ejecución de un *summary* se puede observar la naturaleza de los datos y parte de su distribución. Aunque este tipo de resumen puede resultar de gran utilidad, es necesario tener en cuenta que en ciertos casos puede llevar a equívocos puesto que se podría obviar el significado de ciertos atributos, fundamentalmente en aquellos categóricos de tipo numérico.En cambio, en el caso de atributos no categóricos de tipo numérico se puede extraer información de mayor interés. 
En este caso se observa que el precio de los billetes es 32.2 de media y se aprecia que el valor máximo se aleja mucho de éste, por lo que podría ser un valor erroneo.
En cuanto al número de familias viajando en la nave se podría decir que conforman una minoría y que lo más común son viajeros individuales o con un único familiar o pareja.
La distribución de edad es relativamente baja por lo que se puede suponer que la mayoría de pasajeros son jóvenes (por debajo de 40 años).

```{r}
#Previsualizacion de datos
head(train)
tail(train)
```

En ciertas ocasiones, la previsualización de los datos tal y como se han cargado puede ayudar a la identificación de ciertos detalles de los distintos atributos, tanto en cuanto a su significado como en cuanto a los valores que pueden tomar. En este caso se puede observar que los tipos de datos y sus valores coinciden con la definición de los atributos aunque salen a la luz otro factores como:

* Existencia de valores no numéricos para el atributo *Age*.
* Valores vacíos en el atributo no numérico *Cabin*

Aunque este método aporta cierta luz sobre los datos, no es suficiente, y por ello se deben llevar a cabo otras tareas para la correcta comprensión del conjunto de datos.

```{r}
# Estadísticas de valores vacíos
colSums(is.na(train))
colSums(train=="")
```

Aparentemente, en el conjunto existe una alta cantidad de valores inválidos para el atributo *Age*, teniendo en cuenta que el conjunto cuenta con 891 registros. En cuanto a las cabinas se puede suponer que no todos los pasajeros contaban con una propia y por ello ese campo aparece vacío ya que la mayoría de pasajeros se encuentran con esta carencia. Sin embargo, en cuanto al atributo *Embarked* si que podemos concluir en que existen 2 registros que no fueron tomados y por lo tanto el conjunto de datos carece de dicha información.

## Preparación del dataset.

Tras las observaciones llevadas a cabo en el apartado anterior se realizarán ciertas tareas y acciones sobre el conjunto de datos en vistas a facilitar y mejorar los resultados del futuro análisis.

### Tratamiento de valores nulos o vacíos.

En cuanto a los valores no numéricos encontrados para el atributo *Age*, dado que su eliminación sería una pérdida significativa para los análisis posteriores, se lleva a cabo la sustitucion de estos valores inválidos por el valor medio del atributo.

```{r}
# Tomamos la media para valores vacíos de la variable "Age"
train$Age[is.na(train$Age)] <- mean(train$Age,na.rm=T)
```

Tratándose del atributo *Embarked*, como se ha mostrado anteriormente solo existen 2 registros vacíos con lo que se puede eliminar perfectamente la información de estos pasajeros.

```{r}
# Se eliminan las filas co
train <- train[train$Embarked!="",]
```

En cuanto al atributo *Cabin* dada la suposición antes mencionada se considera que es un valor válido que implica la carencia de un camarote por lo que se procede a asignar un valor más representativo como podría ser "Sin camarote".

```{r}
# Asignamos un valor significativo a los registros sin camarote
train$Cabin[train$Cabin == ""] <- "Sin camarote"
```

### Discretización de variables.

Para el caso del atributo de edad será mas interesante tratarlo como si fuese una categoría por lo que se lleva a cabo una discretización que resultará en la existencia de 8 rangos de edad.

```{r, eval=FALSE}
# Se discretiza Age
train$Age <- cut(train$Age, breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 100), labels = c("0-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-80"))
# Se previsualizan los datos
head(train)
```

### Factorización de variables
Cambiamos el tipo de los atributos que lo necesitan a factor

```{r}
# Transformación
train$Survived <- as.factor(train$Survived)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
train$Embarked <- as.factor(train$Embarked)
```



## Análisis de los datos.

### Selección de los grupos de datos que se quieren analizar
A continuación, se seleccionan los subconjuntos de datos que pueden resultar interesante para analizar:

```{r}
# agrupación por supervivencia
train.vive <- train[train$Survived == 1, ]
train.muere <- train[train$Survived == 0, ]

# agrupación por clase
train.primera <- train[train$Pclass == 1, ]
train.segunda <- train[train$Pclass == 2, ]
train.tercera <- train[train$Pclass == 3, ]

# agrupación por género
train.hombre <- train[train$Sex == "male", ]
train.mujer <- train[train$Sex == "female", ]

# agrupación por rango de edad
train.r1 <- train[train$Age == "0-9", ]
train.r2 <- train[train$Age == "10-19", ]
train.r3 <- train[train$Age == "20-29", ]
train.r4 <- train[train$Age == "30-39", ]
train.r5 <- train[train$Age == "40-49", ]
train.r6 <- train[train$Age == "50-59", ]
train.r7 <- train[train$Age == "60-69", ]
train.r8 <- train[train$Age == "70-80", ]


# agrupación por puerto de embarque
train.pc <- train[train$Embarked == "C", ]
train.pq <- train[train$Embarked == "Q", ]
train.ps <- train[train$Embarked == "S", ]

```


### Comprobación de la normalidad y homogeneidad de la varianza

***
http://www.sthda.com/english/wiki/normality-test-in-r

Visual inspection, described in the previous section, is usually unreliable. It’s possible to use a significance test comparing the sample distribution to a normal one in order to ascertain whether data show or not a serious deviation from normality.

There are several methods for normality test such as Kolmogorov-Smirnov (K-S) normality test and Shapiro-Wilk’s test.

The null hypothesis of these tests is that “sample distribution is normal”. If the test is significant, the distribution is non-normal.

Shapiro-Wilk’s method is widely recommended for normality test and it provides better power than K-S. It is based on the correlation between the data and the corresponding normal scores.

Note that, normality test is sensitive to sample size. Small samples most often pass normality tests. Therefore, it’s important to combine visual inspection and significance test in order to take the right decision.

The R function shapiro.test() can be used to perform the Shapiro-Wilk test of normality for one variable (univariate):
***

```{r}
shapiro.test(as.numeric(train$Pclass))
```

```{r}
shapiro.test(train$Age)
```


```{r}
shapiro.test(train$Fare)
```

...Las variables numéricas (Age antes de discretizarlo) siguen una distribución normal...


### Aplicación de pruebas estadísticas para comparar los grupos de datos




Nos proponemos analizar las relaciones entre las diferentes variables del conjunto de datos para ver si se relacionan y como. Empezamos con las variables categóricas y su relación con Survived

```{r, fig.width=10}
# Visualizamos la relación entre las variables:
g1 <- ggplot(data=train, aes(x=Pclass, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()

g2 <- ggplot(data=train, aes(x=Sex, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()


g3 <- ggplot(data=train, aes(x=Age, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()

g4 <- ggplot(data=train, aes(x=Embarked, fill = Survived)) +
  geom_bar(position = "stack") +
  theme_minimal()

grid.arrange(g1, g2, g3, g4, nrow = 2, ncol = 2)

"
código para estructura de gráficos
ggpairs(train,
        columns = c('Pclass', 'Sex', 'Embarked'),
        aes(color = Survived),
        #axisLabels='internal'
        upper  = list(discrete = 'blank')
        ) +
  theme_minimal()
"

```


```{r, fig.width=10}
# Visualizamos la relación entre las variables, pero como porcentaje:
g1 <- ggplot(data=train, aes(x=Pclass, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()

g2 <- ggplot(data=train, aes(x=Sex, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()


g3 <- ggplot(data=train, aes(x=Age, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()

g4 <- ggplot(data=train, aes(x=Embarked, fill = Survived)) +
  geom_bar(position = "fill") +
  theme_minimal()

grid.arrange(g1, g2, g3, g4, nrow = 2, ncol = 2)

```

Con estos 4 pares de visaualizaciones podemos llegar a los siguientes razonamientos:

* A pesar de que el número de pasajeros de la clase 3 es muy superior, en porcentaje es más bajo que los de la clase 1 y 2.
* Ocurre algo parecido con el género, a pesar de haber menos mujeres, el porcentaje de supervivencia es muy superior, parece que se le dio preferencia a las mujeres a la hora de embarcar en los botes salvavidas.
* Del mismo, llegamos a la conclusión de preferencia para los niños menores de 10 años, a partir de esta edad, el porcentaje se estabiliza hasta llegar a la decada de los 60 y 70 años, donde el porcentaje de supervivientes disminuye de manera significativa. Esto implicaría que se priorizó a las personas más jóvenes frente a las de edad avanzada.
* Respecto a la variable Embarked, solo podemos observar que el número de pasajeros que embarcó en Southampton es mucho mayor que el resto, sin embargo, el porcentaje de supervivientes es menor. Se podría trabajar el puerto C (Cherburgo) para intentar explicar la diferencia en los datos. Quizás, porcentualmente embarcaron más mujeres, niños o gente de primera clase

Obtenemos ahora una matriz de porcentajes de frecuencia.
Vemos, por ejemplo que la probabilidad de sobrevivir si se embarcó en "C" es de un 55.36%

```{r}
t<-table(train$Embarked,train$Survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```


A continuación, se muestran visualizaciones que relacionan las variables categóricas entre sí, sin tener en cuenta la superviviencia. De esta manera buscaremos correlaciones de una manera muy visual.
```{r, fig.height=8, fig.width=10}
# Observamos las posibles relaciones entre las variables categóricas
g1 <- ggplot(data=train, aes(x=Pclass, y=Sex)) +
  geom_jitter() +
  theme_minimal()

g2 <- ggplot(data=train, aes(x=Pclass, y=Embarked)) +
  geom_jitter() +
  theme_minimal()

g3 <- ggplot(data=train, aes(x=Embarked, y=Sex)) +
  geom_jitter() +
  theme_minimal()

grid.arrange(g1, g2, g3, nrow = 2, ncol = 2)
```

Con estos tres gráficos se llega a las siguientes conclusiones:

* La distribución de mujeres en las diferentes clases es mucho más homogénea que la de hombres, que se concentran en la tercera clase.
* En la gráfica que relaciona el puerto de embarque con la clase observamos que proporcionalmente, los embarque de primera clase en el puerto C son mayores, por ello, junto con la gráfica porcentaje de supervivencia respecto a la clase, no se sobrevive más por embarcar en C, sino por ser de primera clase. Mostramos la tabla de probabilidades que nos ayuda a verlo numéricamente.


```{r}
t<-table(train$Embarked,train$Pclass)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```

* El último gráfico relaciona el género con el puerto de embarque. Observamos que la mayoría de registros se encuentra en masculino-S, esto, junto con el resto de gráficos, nos ayuda a comprender que el puerto S es donde embarcaron más personas de 3ª clase, que en su mayoría son hombres.


Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar con 3 variables: Embarked, Survived y Pclass.  

```{r}
# Ahora, podemos dividir el gráfico de Embarked por Pclass:
ggplot(data = train,aes(x=Embarked,fill=Survived)) +
  geom_bar(position="fill") +
  facet_wrap(~Pclass) +
  theme_minimal()
```

Esta visualzación nos ayuda a comprender que la probabilidad de supervivencia está más relacionada con la clase que con el lugar de embarque.

Comparemos ahora dos gráficos de frecuencias: Survived-SibSp y Survived-Parch

```{r}
# Survivial como función de SibSp y Parch
ggplot(data = train,aes(x=SibSp,fill=Survived)) +
  geom_bar() +
  theme_minimal()

ggplot(data = train,aes(x=Parch,fill=Survived)) +
  geom_bar() +
  theme_minimal()
```

Observamos como las forma de estos dos gráficos es similar. Este hecho nos puede indicar presencia de correlaciones altas y que la mayoría de personsas viajaron sin familia.


Veamos un ejemplo de construcción de una variable nueva: Tamaño de familia

```{r}
# Construimos un atributo nuevo: family size.
train$FamilySize <- train$SibSp + train$Parch +1;
train1<-train
ggplot(data = train1[!is.na(train$FamilySize),],aes(x=FamilySize,fill=Survived)) +
  geom_histogram(binwidth =1,position="fill") +
  ylab("Frecuencia") +
  theme_minimal()
```

## Conclusiones.

